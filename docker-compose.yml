services:
  db:
    image: pgvector/pgvector:pg17
    restart: always
    hostname: postgres-db
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready", "-d", "db_prod"]
      interval: 60s
      start_interval: 1s
      timeout: 10s
      retries: 5
      start_period: 80s
    networks:
      - internal
    environment:
      - POSTGRES_USER=root
      - POSTGRES_PASSWORD=secret
    volumes:
      # - db:/var/lib/postgresql/data
      - ./test_db/data:/var/lib/postgresql/data
  cache:
    image: redis:6.2-alpine
    restart: always
    hostname: redis-cache
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 60s
      start_interval: 1s
      timeout: 3s
      retries: 10
      start_period: 15s
    networks:
      - internal
  app:
    image: ${REGISTRY-}yappr-app${VERSION-}
    build:
      context: .
      target: app
    networks:
      - internal
    ports:
      - "5000:5000"
    environment:
      DB_URI: "postgresql+psycopg://root:secret@postgres-db:5432/postgres"
      REDIS_URI: "redis://redis-cache:6379/0"
    env_file:
      - path: .env
        required: false
    volumes:
      - app:/var/lib/yappr/data
      - app-cache:/var/lib/yappr/cache #optional
      - app-nltk:/root/nltk_data
    depends_on:
      cache:
        condition: service_healthy
      db:
        condition: service_healthy
    develop:
      watch:
        - action: sync
          path: ./app/
          target: /src/app/
        - action: sync
          path: ./frontend/
          target: /src/frontend/
        - action: rebuild
          path: ./pyproject.toml
        - action: rebuild
          path: ./uv.lock
  worker-gpu:
    extends: app
    image: ${REGISTRY-}yappr-worker-gpu${VERSION-}
    ports: !reset []
    build:
      target: worker-gpu
    depends_on: !reset[]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - LD_LIBRARY_PATH=/usr/local/nvidia/lib64
    deploy:
      replicas: 0
      resources:
        reservations:
          devices:
          - driver: cdi
            capabilities:
              - gpu
            device_ids:
              - nvidia.com/gpu=all
  worker:
    extends: app
    image: ${REGISTRY-}yappr-worker${VERSION-}
    ports: !reset []
    command: ["--app","app.main.celery","worker","--loglevel=info","--concurrency=1"]
    environment:
      - SERVICE_NAME=worker
    build:
      target: worker
    depends_on:
      - app
    deploy:
      replicas: 1
  worker-priority:
    extends: worker
    command: ["--app","app.main.celery","worker","--loglevel=info","--concurrency=1", "-Q", "priority-queue"]
    environment:
      - SERVICE_NAME=worker-priority
    deploy:
      replicas: 1
  beat:
    extends: worker
    command: ["--app","app.main.celery","beat","--loglevel=info" ]
    environment:
      - SERVICE_NAME=beat
    deploy:
      replicas: 0
  bot:
    image: ${REGISTRY-}yappr-bot${VERSION-}
    stop_signal: SIGINT          # ensure the bot can handle the shutdown signal
    stop_grace_period: 5s        # wait 5 s before SIGKILL
    build:
      context: .
      target: bot
    networks:
      - internal
    env_file:
      - path: .env
        required: false
    depends_on:
      cache:
        condition: service_healthy
      db:
        condition: service_healthy
    deploy:
      replicas: 0
    develop:
      watch:
        - action: sync+restart
          path: ./app/
          target: /src/app/
        - action: sync+restart
          path: ./bot/
          target: /src/bot/
        - action: rebuild
          path: ./pyproject.toml
        - action: rebuild
          path: ./uv.lock
    
volumes:
  # db:
  app:
  app-cache:
  app-nltk:
networks:
  internal:
    driver: bridge
